---
id: lgs9kqn3iirui3exbo0y782
title: Pitfalls of Graph Neural Network Evaluation
desc: ''
updated: 1669501708990
created: 1669501708990
isDir: false
---
## Metadata

- Title: [[Pitfalls of Graph Neural Network Evaluation|dendron://Zendron/zendron.import.title.pitfalls-of-graph-neural-network-evaluation]]
- Authors: [[Oleksandr Shchur|dendron://Zendron/zendron.import.authors.oleksandr-shchur]], [[Maximilian Mumme|dendron://Zendron/zendron.import.authors.maximilian-mumme]], [[Aleksandar Bojchevski|dendron://Zendron/zendron.import.authors.aleksandar-bojchevski]], [[Stephan GÃ¼nnemann|dendron://Zendron/zendron.import.authors.stephan-gÃ¼nnemann]]
- Date: [[2019-06-18|dendron://Zendron/zendron.import.date.2019.06.18]]
- Date Accessed: [[2022-10-06|dendron://Zendron/zendron.import.date.2022.10.06]]
- Date Added: [[2022-10-06-18-47-34|dendron://Zendron/zendron.import.date.2022.10.06.18.47.34]]
- Date Modified: [[2022-11-26-20-12-30|dendron://Zendron/zendron.import.date.2022.11.26.20.12.30]]
- URL: [http://arxiv.org/abs/1811.05868](http://arxiv.org/abs/1811.05868)
- DOI: [10.48550/arXiv.1811.05868](http://doi.org/10.48550/arXiv.1811.05868)
- Citation Key: [[shchurPitfallsGraphNeural2019|user.shchurpitfallsgraphneural2019]]
- Citations: 556 citations (Semantic Scholar/arXiv) [2022-11-26]
- Publication Title: No publication title
- Journal Abbreviation: No publication title
- Item Type: [[preprint|dendron://Zendron/zendron.import.item-type.preprint]]
- PDF Attachments: [Online PDF attachment](https://www.zotero.org/groups/9025336/mjvolk3/items/9025336/attachment/IRZ2H8GP/reader)
- Tags: #Computer Science - Machine Learning, #Computer Science - Social and Information Networks, #Statistics - Machine Learning, #ðŸ¦ŒðŸ“š
- Local Library: [Local Library](zotero://select/items/9025336)
- Cloud Library: [Cloud Library](https://www.zotero.org/groups/9025336/mjvolk3/library)

## Abstract
Semi-supervised node classification in graphs is a fundamental problem in graph mining, and the recently proposed graph neural networks (GNNs) have achieved unparalleled results on this task. Due to their massive success, GNNs have attracted a lot of attention, and many novel architectures have been put forward. In this paper we show that existing evaluation strategies for GNN models have serious shortcomings. We show that using the same train/validation/test splits of the same datasets, as well as making significant changes to the training procedure (e.g. early stopping criteria) precludes a fair comparison of different architectures. We perform a thorough empirical evaluation of four prominent GNN models and show that considering different splits of the data leads to dramatically different rankings of models. Even more importantly, our findings suggest that simpler GNN architectures are able to outperform the more sophisticated ones if the hyperparameters and the training procedure are tuned fairly for all models.

## Local Note
[[Local Note|dendron://Zendron/zendron.local.pitfalls-of-graph-neural-network-evaluation]]
